{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import eager as tfe\n",
    "tf.executing_eagerly()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import gym as gym\n",
    "from gym.wrappers import Monitor\n",
    "from gym import logger as gymlogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "      pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size=1e6):\n",
    "        self.storage = []\n",
    "        self.max_size = max_size\n",
    "        self.ptr = 0\n",
    "\n",
    "    def add(self, data):\n",
    "        if len(self.storage) == self.max_size:\n",
    "            self.storage[int(self.ptr)] = data\n",
    "            self.ptr = (self.ptr + 1) % self.max_size\n",
    "        else:\n",
    "            self.storage.append(data)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "        x, y, u, r, d = [], [], [], [], []\n",
    "\n",
    "        for i in ind: \n",
    "            X, Y, U, R, D = self.storage[i]\n",
    "            x.append(np.array(X, copy=False))\n",
    "            y.append(np.array(Y, copy=False))\n",
    "            u.append(np.array(U, copy=False))\n",
    "            r.append(np.array(R, copy=False))\n",
    "            d.append(np.array(D, copy=False))\n",
    "\n",
    "        return np.array(x), np.array(y), np.array(u), np.array(r).reshape(-1, 1), np.array(d).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifying\n",
    "\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, action_dim, max_action):\n",
    "        super().__init__(self)\n",
    "        self.max_action = max_action\n",
    "        self.dense1 = tf.keras.layers.Dense(units=40, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform(),\n",
    "                                            activation= tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=30, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform(),\n",
    "                                            activation= tf.nn.relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=action_dim, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform()\n",
    "                                           )\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        result = self.dense1(inputs)\n",
    "        result = self.dense2(result)\n",
    "        result = self.dense3(result)\n",
    "        result = self.max_action * tf.nn.tanh(result)\n",
    "\n",
    "        \n",
    "        return result\n",
    "\n",
    "    \n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, action_dim, wd = 1e-2):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        self.layer1 = tf.keras.layers.Dense(40, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "                                            bias_regularizer= tf.keras.regularizers.l2(wd),\n",
    "                                            activation= tf.nn.relu)\n",
    "        self.layer2 = tf.keras.layers.Dense(30, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "                                            bias_regularizer= tf.keras.regularizers.l2(wd),\n",
    "                                            activation= tf.nn.relu)\n",
    "        self.layer3 = tf.keras.layers.Dense(1, \n",
    "                                            kernel_initializer= tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "                                            bias_regularizer= tf.keras.regularizers.l2(wd)\n",
    "                                           )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x, n = inputs\n",
    "        \n",
    "        result = self.layer1(x)\n",
    "        result = tf.concat([result, n], axis = 1)\n",
    "        result = self.layer2(result)\n",
    "        result = self.layer3(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORIGINAL ACTOR & CRITIC\n",
    "\n",
    "# class Actor(tf.keras.Model):\n",
    "#     def __init__(self, action_dim, max_action, name = 'Actor'):\n",
    "#         super().__init__(name = name)\n",
    "#         self.max_action = max_action\n",
    "#         self.layer1 = tf.keras.layers.Dense(400, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             activation= tf.nn.relu,\n",
    "#                                             name = \"Layer1\")\n",
    "#         self.layer2 = tf.keras.layers.Dense(300, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             activation= tf.nn.relu,\n",
    "#                                             name = \"Layer2\")\n",
    "#         self.layer3 = tf.keras.layers.Dense(action_dim, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             name = \"Layer3\")\n",
    "        \n",
    "        \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         result = self.layer1(inputs)\n",
    "#         result = self.layer2(result)\n",
    "#         result = self.layer3(result)\n",
    "#         action = self.max_action * tf.nn.tanh(result)\n",
    "        \n",
    "#         return action\n",
    "    \n",
    "    \n",
    "# class Critic(tf.keras.Model):\n",
    "#     def __init__(self, action_dim, wd = 1e-2, name = 'Critic'):\n",
    "#         super().__init__(name = name)\n",
    "        \n",
    "#         self.layer1 = tf.keras.layers.Dense(400, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             bias_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             activation= tf.nn.relu,\n",
    "#                                             name = \"Layer1\")\n",
    "#         self.layer2 = tf.keras.layers.Dense(300, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             bias_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             activation= tf.nn.relu,\n",
    "#                                             name = \"Layer2\")\n",
    "#         self.layer3 = tf.keras.layers.Dense(action_dim, \n",
    "#                                             kernel_initializer= PytorchInitializer(),\n",
    "#                                             kernel_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             bias_regularizer= tf.keras.regularizers.l2(wd),\n",
    "#                                             name = \"Layer3\")\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         x, n = inputs\n",
    "        \n",
    "#         result = self.layer1(x)\n",
    "#         inner_feat = tf.concat([result, n], axis = 1)\n",
    "#         result = self.layer2(inner_feat)\n",
    "#         result = self.layer3(result)\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers\n",
    "losses = tf.keras.losses\n",
    "\n",
    "class DDPG(object):\n",
    "    def __init__(self,  env, continiuous = True):\n",
    "        self.env = env\n",
    "        self.continiuous = continiuous\n",
    "        self.steps_before_train = 2000\n",
    "        self.memory_capacity = 100000\n",
    "        self.batch_size = 128\n",
    "        self.memory = ReplayBuffer()\n",
    "        self.expl_noise = 0.4 # Std of Gaussian exploration noise\n",
    "        self.actor_globalsteps = tf.compat.v1.train.get_or_create_global_step()\n",
    "        self.critic_globalsteps = tf.compat.v1.train.get_or_create_global_step()\n",
    "        self.steps = 0\n",
    "        self.vlolume = 50\n",
    "        self.total_rewards = []\n",
    "        \n",
    "        \n",
    "        self.max_action = self.env.action_space.high\n",
    "        if self.env.action_space.shape == ():\n",
    "            self.action_dim = env.action_space.n\n",
    "        else:\n",
    "            self.action_dim = env.action_space.shape[0]\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        \n",
    "        \n",
    "        self.actor = Actor(self.action_dim, self.max_action)\n",
    "        self.actor_target = Actor(self.action_dim, self.max_action)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
    "        \n",
    "        #initialize target network\n",
    "        for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "            target_param.assign(param)\n",
    "        \n",
    "        self.critic = Critic(self.action_dim)\n",
    "        self.critic_target = Critic(self.action_dim)\n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(learning_rate= 0.002)\n",
    "        \n",
    "         #initialize target network\n",
    "        for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "            target_param.assign(param)\n",
    "            \n",
    "    def select_action(self, state):\n",
    "        \"\"\"\n",
    "        :Select Continious Action:\n",
    "        \"\"\"\n",
    "        \n",
    "        state = np.expand_dims(state, axis = 0).astype(np.float32)\n",
    "        action = self.actor(state).numpy()\n",
    "#         print(action)\n",
    "        return action[0]\n",
    "\n",
    "    def run(self, env = gym.make('CartPole-v0')):\n",
    "        self.env = env\n",
    "        s = self.env.reset()\n",
    "        step = 0\n",
    "        while True:\n",
    "            action = self.select_action(s)\n",
    "            s_1, reward, done, info = self.env.step(action)\n",
    "            s = s_1\n",
    "            step += 1\n",
    "\n",
    "            if done:\n",
    "                print(\"Episode finished successfully after {} timesteps\".format(step))\n",
    "                break\n",
    "\n",
    "        self.env.close()   \n",
    "\n",
    "    def train(self, episodes):\n",
    "        \n",
    "        \n",
    "        ## Pre-train to store memory\n",
    "        for epoch in range(episodes):\n",
    "            epoch_reward = 0\n",
    "            s = self.env.reset()\n",
    "\n",
    "            \n",
    "            \n",
    "            while True:\n",
    "                if self.steps < self.steps_before_train:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    self.learn()\n",
    "                    action = self.select_action(s)\n",
    "                    if (self.expl_noise != 0) & self.continiuous:\n",
    "                        # Noise:  action = action + normal distribution(mean =0, std = expl_noise)\n",
    "                        action = (action + np.random.normal(0, self.expl_noise, size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
    " \n",
    "                s_1, reward, done, _ = self.env.step(action)\n",
    "                \n",
    "                self.memory.add((s, s_1, action, reward / 10, done))\n",
    "                                    \n",
    "                s = s_1\n",
    "                self.steps += 1\n",
    "                \n",
    "                epoch_reward += reward\n",
    "                \n",
    "                if done:\n",
    "                    self.total_rewards.append(np.round(epoch_reward,3))\n",
    "                    break\n",
    "\n",
    "            if epoch % self.vlolume == 0:\n",
    "                print('Episode trained...', epoch)\n",
    "           \n",
    "                \n",
    "        \n",
    "#     @tf.contrib.eager.defun\n",
    "    def learn(self, gamma = 0.99, tau = 0.005):\n",
    "\n",
    "        s, s_1, a, r, done = self.memory.sample(self.batch_size)\n",
    "\n",
    "        s = tf.constant(s, dtype = tf.float32)\n",
    "        a = tf.constant(a, dtype = tf.float32)\n",
    "        s_1 = tf.constant(s_1, dtype = tf.float32)\n",
    "        r = tf.constant(r, dtype = tf.float32)\n",
    "        done = tf.constant(done, dtype = tf.float32)\n",
    "        \n",
    "#         s = np.array(s, dtype = np.float32)\n",
    "#         a = np.array(a, dtype = np.float32)\n",
    "#         s_1 = np.array(s_1, dtype = np.float32)\n",
    "#         r = np.array(r, dtype = np.float32)\n",
    "#         done = np.array(done, dtype = np.float32)\n",
    "\n",
    "\n",
    "        not_done = 1-done\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            s_1_target = self.actor_target(s)\n",
    "            target_Q = self.critic_target([s_1, s_1_target])\n",
    "            target_Q = r + (not_done * gamma * target_Q)\n",
    "            current_Q = self.critic([s, a])\n",
    "\n",
    "            # Compute Critic Loss + L2 Loss\n",
    "            loss = tf.reduce_mean((current_Q - target_Q) ** 2)\n",
    "            critic_loss = tf.reduce_mean(loss + 0.5 * tf.add_n(self.critic.losses))\n",
    "\n",
    "        critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grads, self.critic.trainable_variables),\n",
    "#                                               global_step= self.critic_globalsteps\n",
    "                                             )\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            action = self.actor(s)\n",
    "            actor_loss = - tf.reduce_mean(self.critic([s, action]))\n",
    "            \n",
    "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grads, self.actor.trainable_variables),\n",
    "#                                              global_step= self.actor_globalsteps\n",
    "                                            )\n",
    "\n",
    "        \n",
    "        ## Update target networks every step (smoothing method) (can be periodic)\n",
    "\n",
    "        for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "            target_param.assign( tau * param + (1-tau) * target_param)\n",
    "\n",
    "        for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "            target_param.assign( tau * param + (1-tau) * target_param)\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDPGAgent = DDPG(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode trained... 1\n",
      "Episode trained... 51\n"
     ]
    }
   ],
   "source": [
    "DDPGAgent.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1167.482\n",
       "1     -969.347\n",
       "2    -1002.271\n",
       "3     -757.887\n",
       "4    -1052.383\n",
       "5    -1163.809\n",
       "6    -1225.517\n",
       "7    -1696.932\n",
       "8    -1501.348\n",
       "9     -788.879\n",
       "10   -1605.415\n",
       "11   -1505.821\n",
       "12   -1312.525\n",
       "13   -1571.579\n",
       "14   -1080.077\n",
       "15    -945.304\n",
       "16   -1552.692\n",
       "17   -1455.236\n",
       "18   -1366.067\n",
       "19   -1542.825\n",
       "20   -1317.884\n",
       "21   -1527.566\n",
       "22   -1534.878\n",
       "23   -1402.223\n",
       "24   -1295.118\n",
       "25   -1637.385\n",
       "26    -919.921\n",
       "27   -1597.007\n",
       "28   -1355.986\n",
       "29   -1193.636\n",
       "30   -1491.483\n",
       "31   -1181.475\n",
       "32   -1535.526\n",
       "33   -1487.057\n",
       "34   -1191.911\n",
       "35   -1544.154\n",
       "36   -1132.177\n",
       "37   -1508.688\n",
       "38    -785.641\n",
       "39    -654.544\n",
       "40    -454.929\n",
       "41    -268.663\n",
       "42    -132.765\n",
       "43    -262.823\n",
       "44    -267.394\n",
       "45    -137.024\n",
       "46    -127.550\n",
       "47    -263.580\n",
       "48    -436.328\n",
       "49    -258.418\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(DDPGAgent.total_rewards).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "\n",
    "\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1068.429\n",
       "1    -1685.527\n",
       "2    -1091.502\n",
       "3    -1607.830\n",
       "4     -916.388\n",
       "5    -1550.092\n",
       "6    -1159.105\n",
       "7    -1665.014\n",
       "8     -940.275\n",
       "9    -1171.301\n",
       "10   -1631.888\n",
       "11   -1636.529\n",
       "12   -1066.892\n",
       "13   -1062.668\n",
       "14   -1130.883\n",
       "15   -1543.263\n",
       "16   -1629.084\n",
       "17   -1330.657\n",
       "18   -1531.145\n",
       "19   -1482.543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(DDPGAgent.total_rewards).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13a127968d0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DDPGAgent.total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Monitor.__del__ at 0x00000137DEA9B950>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Z00041331\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\", line 229, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Z00041331\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\", line 140, in close\n",
      "    self._close_video_recorder()\n",
      "  File \"C:\\Users\\Z00041331\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\", line 212, in _close_video_recorder\n",
      "    self.video_recorder.close()\n",
      "  File \"C:\\Users\\Z00041331\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\", line 129, in close\n",
      "    os.remove(self.path)\n",
      "FileNotFoundError: [WinError 2] 系統找不到指定的檔案。: 'D:\\\\Python\\\\RL\\\\video\\\\openaigym.video.0.2496.video000000.mp4'\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c9918f8975ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pendulum-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mDDPGAgent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mshow_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ba853f60a638>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CartPole-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         )\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_ansi_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_image_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36m_encode_image_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_encode_image_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes_per_sec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoder_version'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, output_path, frame_shape, frames_per_sec)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ffmpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "\n",
    "env = wrap_env(gym.make('Pendulum-v0'))\n",
    "\n",
    "DDPGAgent.run(env)\n",
    "show_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(hwnd, msg, wParam, lParam)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_window_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhwnd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwParam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mevent_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(hwnd, msg, wParam, lParam)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_window_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhwnd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwParam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mevent_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-34780908d6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MountainCarContinuous-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mDDPGAgent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mshow_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ba853f60a638>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CartPole-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         )\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ansi'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\continuous_mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mdispatch_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPeekMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPM_REMOVE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTranslateMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatchMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env = wrap_env(gym.make('MountainCarContinuous-v0'))\n",
    "\n",
    "DDPGAgent.run(env)\n",
    "show_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -34.201\n",
       "1    -33.428\n",
       "2    -27.757\n",
       "3    -36.140\n",
       "4    -16.635\n",
       "5    -16.563\n",
       "6    -16.888\n",
       "7    -15.801\n",
       "8    -17.096\n",
       "9    -15.577\n",
       "10   -15.581\n",
       "11   -15.832\n",
       "12   -16.491\n",
       "13   -15.755\n",
       "14   -16.186\n",
       "15   -17.130\n",
       "16   -17.628\n",
       "17   -15.991\n",
       "18   -16.305\n",
       "19   -14.705\n",
       "20   -15.868\n",
       "21   -16.308\n",
       "22   -18.002\n",
       "23   -17.541\n",
       "24   -17.166\n",
       "25   -22.535\n",
       "26   -42.315\n",
       "27   -54.242\n",
       "28   -69.813\n",
       "29   -73.242\n",
       "30   -71.918\n",
       "31   -73.805\n",
       "32   -74.428\n",
       "33   -74.743\n",
       "34   -77.023\n",
       "35   -73.431\n",
       "36   -74.515\n",
       "37   -75.870\n",
       "38   -74.736\n",
       "39   -77.683\n",
       "40   -74.382\n",
       "41   -77.014\n",
       "42   -74.870\n",
       "43   -74.914\n",
       "44   -74.648\n",
       "45   -76.457\n",
       "46   -74.760\n",
       "47   -76.587\n",
       "48   -75.305\n",
       "49   -76.362\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(DDPGAgent.total_rewards).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, state_dim, action_dim, max_action, name=\"Actor\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.l1 = layers.Dense(400, kernel_initializer=PytorchInitializer(),\n",
    "                               name=\"L1\")\n",
    "        self.l2 = layers.Dense(300, kernel_initializer=PytorchInitializer(),\n",
    "                               name=\"L2\")\n",
    "        self.l3 = layers.Dense(action_dim, kernel_initializer=PytorchInitializer(),\n",
    "                               name=\"L3\")\n",
    "\n",
    "\n",
    "        self.max_action = max_action\n",
    "\n",
    "        # 後段の処理のために早めにshapeを確定させる\n",
    "        dummy_state = tf.constant(np.zeros(shape=[1, state_dim], dtype=np.float32))\n",
    "        self(dummy_state)\n",
    "\n",
    "    def call(self, inputs):\n",
    "#         with tf.device(\"/gpu:0\"):\n",
    "        features = tf.nn.relu(self.l1(inputs))\n",
    "        features = tf.nn.relu(self.l2(features))\n",
    "        features = self.l3(features)\n",
    "        action = self.max_action * tf.nn.tanh(features)\n",
    "        return action\n",
    "\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, state_dim, action_dim, wd=1e-2, name=\"Critic\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.l1 = layers.Dense(400, kernel_initializer=PytorchInitializer(),\n",
    "                               kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd),\n",
    "                               name=\"L1\")\n",
    "        self.l2 = layers.Dense(300, kernel_initializer=PytorchInitializer(),\n",
    "                               kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd),\n",
    "                               name=\"L2\")\n",
    "        self.l3 = layers.Dense(1, kernel_initializer=PytorchInitializer(),\n",
    "                               kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd),\n",
    "                               name=\"L3\")\n",
    "\n",
    "        dummy_state = tf.constant(np.zeros(shape=[1, state_dim], dtype=np.float32))\n",
    "        dummy_action = tf.constant(np.zeros(shape=[1, action_dim], dtype=np.float32))\n",
    "        self([dummy_state, dummy_action])\n",
    "\n",
    "    def call(self, inputs):\n",
    "#         with tf.device(\"/gpu:0\"):\n",
    "        x, u = inputs\n",
    "\n",
    "        x = tf.nn.relu(self.l1(x))\n",
    "        inner_feat = tf.concat([x, u], axis=1)\n",
    "        x = tf.nn.relu(self.l2(inner_feat))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DDPG(tf.contrib.checkpoint.Checkpointable):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        self.actor = Actor(state_dim, action_dim, max_action)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action)\n",
    "\n",
    "        # initialize target network\n",
    "        for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "            target_param.assign(param)\n",
    "\n",
    "        self.actor_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        self.critic = Critic(state_dim, action_dim)\n",
    "        self.critic_target = Critic(state_dim, action_dim)\n",
    "\n",
    "        # initialize target network\n",
    "        for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "            target_param.assign(param)\n",
    "\n",
    "        self.critic_optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        \"\"\"\n",
    "        :param np.ndarray state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert isinstance(state, np.ndarray)\n",
    "        assert len(state.shape) == 1\n",
    "\n",
    "        state = np.expand_dims(state, axis=0).astype(np.float32)\n",
    "        action = self.actor(state).numpy()\n",
    "\n",
    "        return action[0]\n",
    "\n",
    "    def train(self, replay_buffer, iterations, batch_size=64, discount=0.99, tau=0.001):\n",
    "\n",
    "        for it in range(iterations):\n",
    "\n",
    "            state, next_state, action, reward, done = replay_buffer.sample(batch_size)\n",
    "            state = np.array(state, dtype=np.float32)\n",
    "            next_state = np.array(next_state, dtype=np.float32)\n",
    "            action = np.array(action, dtype=np.float32)\n",
    "            reward = np.array(reward, dtype=np.float32)\n",
    "            done = np.array(done, dtype=np.float32)\n",
    "            not_done = 1 - done\n",
    "\n",
    "#             with tf.device(\"/gpu:0\"):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                target_Q = self.critic_target([next_state, self.actor_target(next_state)])\n",
    "                target_Q = reward + (not_done * discount * target_Q)\n",
    "                # detach => stop_gradient\n",
    "                target_Q = tf.stop_gradient(target_Q)\n",
    "\n",
    "                current_Q = self.critic([state, action])\n",
    "\n",
    "                # Compute critic loss + L2 loss\n",
    "                critic_loss = tf.reduce_mean(losses.MSE(current_Q, target_Q)) + 0.5*tf.add_n(self.critic.losses)\n",
    "\n",
    "            critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "            self.critic_optimizer.apply_gradients(zip(critic_grad, self.critic.trainable_variables))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                next_action = self.actor(state)\n",
    "                actor_loss = -tf.reduce_mean(self.critic([state, next_action]))\n",
    "\n",
    "            actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "            self.actor_optimizer.apply_gradients(zip(actor_grad, self.actor.trainable_variables))\n",
    "\n",
    "            # Update target networks\n",
    "            for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "                target_param.assign(tau * param + (1 - tau) * target_param)\n",
    "\n",
    "            for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "                target_param.assign(tau * param + (1 - tau) * target_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DDPG_fast(tf.contrib.checkpoint.Checkpointable):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        self.actor = Actor(state_dim, action_dim, max_action)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action)\n",
    "        self.actor_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        # initialize target network\n",
    "        for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "            target_param.assign(param)\n",
    "\n",
    "        self.critic = Critic(state_dim, action_dim)\n",
    "        self.critic_target = Critic(state_dim, action_dim)\n",
    "        self.critic_optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "\n",
    "        # initialize target network\n",
    "        for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "            target_param.assign(param)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        \"\"\"\n",
    "        :param np.ndarray state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert isinstance(state, np.ndarray)\n",
    "        assert len(state.shape) == 1\n",
    "\n",
    "        state = np.expand_dims(state, axis=0).astype(np.float32)\n",
    "        action = self._select_action_body(tf.constant(state))\n",
    "\n",
    "        return action.numpy()[0]\n",
    "\n",
    "    @tf.contrib.eager.defun\n",
    "    def _select_action_body(self, state):\n",
    "        \"\"\"\n",
    "        :param np.ndarray state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        action = self.actor(state)\n",
    "        return action\n",
    "\n",
    "    def train(self, replay_buffer, iterations, batch_size=64, discount=0.99, tau=0.001):\n",
    "\n",
    "        for it in range(iterations):\n",
    "\n",
    "            state, next_state, action, reward, done = replay_buffer.sample(batch_size)\n",
    "            state = np.array(state, dtype=np.float32)\n",
    "            next_state = np.array(next_state, dtype=np.float32)\n",
    "            action = np.array(action, dtype=np.float32)\n",
    "            reward = np.array(reward, dtype=np.float32)\n",
    "            done = np.array(done, dtype=np.float32)\n",
    "            not_done = 1 - done\n",
    "            self._train_body(state, next_state, action, reward, not_done, discount, tau)\n",
    "\n",
    "    @tf.contrib.eager.defun\n",
    "    def _train_body(self, state, next_state, action, reward, not_done, discount, tau):\n",
    "#         with tf.device(\"/gpu:0\"):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_Q = self.critic_target([next_state, self.actor_target(next_state)])\n",
    "            target_Q = reward + (not_done * discount * target_Q)\n",
    "            # detach => stop_gradient\n",
    "            target_Q = tf.stop_gradient(target_Q)\n",
    "\n",
    "            current_Q = self.critic([state, action])\n",
    "\n",
    "            # Compute critic loss + L2 loss\n",
    "            critic_loss = tf.reduce_mean(losses.MSE(current_Q, target_Q)) + 0.5*tf.add_n(self.critic.losses)\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grad, self.critic.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            next_action = self.actor(state)\n",
    "            actor_loss = -tf.reduce_mean(self.critic([state, next_action]))\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grad, self.actor.trainable_variables))\n",
    "\n",
    "        # Update target networks\n",
    "        for param, target_param in zip(self.critic.weights, self.critic_target.weights):\n",
    "            target_param.assign(tau * param + (1 - tau) * target_param)\n",
    "\n",
    "        for param, target_param in zip(self.actor.weights, self.actor_target.weights):\n",
    "            target_param.assign(tau * param + (1 - tau) * target_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchInitializer(tf.keras.initializers.Initializer):\n",
    "    \"\"\"PytorchのLinearにあわせたinitializer\n",
    "    stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "    self.weight.data.uniform_(-stdv, stdv)\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=1.0, seed=None):\n",
    "        self.seed = seed\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, shape, dtype=None, partition_info=None):\n",
    "        if dtype is None:\n",
    "            dtype = tf.float32\n",
    "\n",
    "        if len(shape) == 1:\n",
    "            fan_in = shape[0]\n",
    "        elif len(shape) == 2:\n",
    "            fan_in = shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"invalid shape\")\n",
    "\n",
    "\n",
    "        scale = self.scale * fan_in\n",
    "\n",
    "        stdv = 1. / tf.math.sqrt(scale)\n",
    "\n",
    "        return tf.random_uniform(\n",
    "            shape, -stdv, stdv, dtype=dtype, seed=self.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
